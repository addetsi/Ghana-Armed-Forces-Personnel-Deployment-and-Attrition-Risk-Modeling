{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca26208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n",
      "Project root: C:\\Users\\hp\\Desktop\\gaf\\Ghana-Armed-Forces-Personnel-Deployment-and-Attrition-Risk-Modeling\n",
      "Random seed: 42\n",
      "Target sample size: 1000 personnel\n",
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#machine learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, \n",
    "    r2_score, mean_absolute_percentage_error\n",
    ")\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import config\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(config.RANDOM_SEED)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb9b742",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9b23a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (1000, 75)\n",
      "Readiness score statistics:\n",
      "count    1000.000000\n",
      "mean       71.153700\n",
      "std         9.110339\n",
      "min        42.400000\n",
      "25%        64.900000\n",
      "50%        71.300000\n",
      "75%        77.525000\n",
      "max        99.300000\n",
      "Name: readiness_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#load dataset \n",
    "data_path = config.PROCESSED_DATA_DIR/config.FEATURES_ENGINEERED_FILE\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Data Shape: {df.shape}\")\n",
    "print(\"Readiness score statistics:\")\n",
    "print(df['readiness_score'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62028b8",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8b72a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1000, 73)\n",
      "Target shape: (1000,)\n",
      "\n",
      "Categorical features: 12\n",
      "\n",
      "Features after encoding: (1000, 100)\n"
     ]
    }
   ],
   "source": [
    "#seperate features and target \n",
    "X = df.drop(['attrition_risk', 'readiness_score'], axis=1)\n",
    "y = df['readiness_score']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "#encode categorical features \n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"\\nCategorical features: {len(categorical_features)}\")\n",
    "\n",
    "#one-hot encode\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "print(f\"\\nFeatures after encoding: {X_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "889e65a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits:\n",
      " Training: 800 samples (80.0%)\n",
      " Test: 200 samples (20.0%)\n"
     ]
    }
   ],
   "source": [
    "#train/test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y,\n",
    "    test_size=config.TEST_SIZE,\n",
    "    random_state=config.RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"Dataset splits:\")\n",
    "print(f\" Training: {X_train.shape[0]} samples ({X_train.shape[0]/len(df):.1%})\")\n",
    "print(f\" Test: {X_test.shape[0]} samples ({X_test.shape[0]/len(df):.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69ddc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#store feature names \n",
    "feature_names = X_encoded.columns.tolist()\n",
    "\n",
    "print(f\"Features scaled\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93af4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
